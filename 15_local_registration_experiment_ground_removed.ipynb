{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy\n",
    "from os import listdir\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "from winsound import Beep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_point_clouds(point_clouds, black_point_cloud = None):\n",
    "    np.random.seed(0)\n",
    "    pc_copy = []\n",
    "    colors = [[1, 0.706, 0], [0, 0.651, 0.929], [0.3, 0.351, 0.529]]\n",
    "    for idx, x in enumerate(point_clouds):\n",
    "        temp = copy.deepcopy(x)\n",
    "        if idx < len(colors):\n",
    "            temp.paint_uniform_color(colors[idx])\n",
    "        else:\n",
    "            temp.paint_uniform_color(np.random.rand(3))\n",
    "        pc_copy.append(temp)\n",
    "    \n",
    "    if black_point_cloud is not None:\n",
    "        temp = copy.deepcopy(black_point_cloud)\n",
    "        temp.paint_uniform_color([249/256,1/256,0])\n",
    "        pc_copy.append(temp)\n",
    "   \n",
    "    o3d.visualization.draw_geometries(pc_copy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = \"C:\\\\Users\\\\amoff\\\\Documents\\\\Meine Textdokumente\\\\Masterarbeit\\\\Daten\\\\rotated_and_translated\\\\100000000\\\\cropped_frames\\\\\"\n",
    "\n",
    "# target_path = \"C:\\\\Users\\\\amoff\\\\Documents\\\\Meine Textdokumente\\\\Masterarbeit\\\\LiDAR_Punktwolke-RevA-201455_Vermessungsdaten\\\\Cleaned Export\\\\intersection_dirty\\\\intersection_dirty2_xyzi_down_transformed_compressed_ground_removed.pcd\"\n",
    "target_path = \"C:\\\\Users\\\\amoff\\\\Documents\\\\Meine Textdokumente\\\\Masterarbeit\\\\LiDAR_Punktwolke-RevA-201455_Vermessungsdaten\\\\Cleaned Export\\\\intersection_dirty\\\\intersection_dirty2_xyzi_down_transformed_compressed_cropped.pcd\"\n",
    "target = o3d.io.read_point_cloud(target_path)\n",
    "voxel_size = 1\n",
    "target = target.voxel_down_sample(voxel_size)\n",
    "target.estimate_normals()\n",
    "\n",
    "filenames = listdir(source_folder)[:]\n",
    "frames = [target]\n",
    "for file in filenames:\n",
    "    frames.append(o3d.io.read_point_cloud(source_folder + file))\n",
    "\n",
    "draw_point_clouds(frames)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_point_clouds(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_registration(source, target):\n",
    "    max_correspondence_distance = 0.5\n",
    "    evaluation = o3d.pipelines.registration.evaluate_registration( source, target, max_correspondence_distance)\n",
    "    print(evaluation.fitness, evaluation.inlier_rmse, evaluation)\n",
    "\n",
    "def transform(point_cloud, transformation):\n",
    "    temp = copy.deepcopy(point_cloud) \n",
    "    return temp.transform(transformation)\n",
    "\n",
    "def compute_icp_p2plane(source, target):\n",
    "    max_correspondence_distance = 10\n",
    "    return o3d.pipelines.registration.registration_icp( source, target, max_correspondence_distance, np.identity(4), o3d.pipelines.registration.TransformationEstimationPointToPlane())\n",
    "\n",
    "def compute_icp_p2p(source, target):\n",
    "    max_correspondence_distance = 10\n",
    "    # return o3d.pipelines.registration.registration_icp( source, target, threshold, np.identity(4), o3d.pipelines.registration.TransformationEstimationPointToPoint(),  o3d.pipelines.registration.ICPConvergenceCriteria(relative_fitness=1.000000e-07, relative_rmse=1.000000e-07,))#max_iteration = 2000,\n",
    "    return o3d.pipelines.registration.registration_icp( source, target, max_correspondence_distance, np.identity(4), o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "\n",
    "def show_transformation(target, source, transformation):\n",
    "    draw_point_clouds([target, transform(source, transformation)], source)\n",
    "    # draw_point_clouds([target, ], source)\n",
    "\n",
    "def rotate(point_cloud, x_degrees,y_degrees = 0, z_degrees = 0):\n",
    "    R = point_cloud.get_rotation_matrix_from_xyz(np.pi/180 * np.array([z_degrees, y_degrees, x_degrees]))\n",
    "    point_cloud.rotate(R)\n",
    "    return R\n",
    "\n",
    "def relative_translation_error(translation_vector1, translation_vector2):\n",
    "    return np.linalg.norm(translation_vector1-translation_vector2)\n",
    "\n",
    "def relative_rotation_error(rotation, ground_truth_rotation):\n",
    "    return np.arccos((np.trace(np.matmul(rotation, ground_truth_rotation))-1)/2)\n",
    "\n",
    "def decompose_transformation_matrix(transformation):\n",
    "    translation = transformation[0:3, 3]\n",
    "    rotation = transformation[0:3, 0:3]\n",
    "    return translation, rotation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "\n",
    "    radius_normal = voxel_size * 2\n",
    "    pcd_down.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "\n",
    "    radius_feature = voxel_size * 5\n",
    "    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature( pcd_down, o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "    return pcd_down, pcd_fpfh\n",
    "\n",
    "def compute_global_registration_no_threshold(source_down, target_down, source_fpfh, target_fpfh, voxel_size):\n",
    "    distance_threshold = 10 #voxel_size * 1.5\n",
    "    return o3d.pipelines.registration.registration_ransac_based_on_feature_matching( source_down, target_down, source_fpfh, target_fpfh, True, distance_threshold)\n",
    "\n",
    "def compute_fast_global_registration(source_down, target_down, source_fpfh, target_fpfh, voxel_size):\n",
    "    distance_threshold = 10 #voxel_size * 0.5\n",
    "    # result = o3d.pipelines.registration.registration_fgr_based_on_feature_matching( source_down, target_down, source_fpfh, target_fpfh, o3d.pipelines.registration.FastGlobalRegistrationOption( maximum_correspondence_distance=distance_threshold))\n",
    "    return o3d.pipelines.registration.registration_fgr_based_on_feature_matching( source_down, target_down, source_fpfh, target_fpfh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_down, target_fpfh = preprocess_point_cloud(target, voxel_size)\n",
    "print(\"Target fpfh computation done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_icp_errors(source_folder, target, method, suffix = \"\", frame_number = None, translation_number = None, show_tran = False):\n",
    "    voxel_size = 1\n",
    "    suffix = method + suffix\n",
    "\n",
    "\n",
    "    filenames = listdir(source_folder)\n",
    "    \n",
    "\n",
    "    frames = []\n",
    "    frames_fpfh = []\n",
    "    if frame_number is not None:\n",
    "        print(f\"Frame number: {frame_number}, method: {method}\")\n",
    "        filenames = [filenames[frame_number]]\n",
    "\n",
    "    for file in filenames:\n",
    "        point_cloud = o3d.io.read_point_cloud(source_folder + file)\n",
    "        source_down, source_fpfh = preprocess_point_cloud(point_cloud, voxel_size)\n",
    "        frames.append(source_down)\n",
    "        frames_fpfh.append(source_fpfh)\n",
    "        \n",
    "    df_translation = pd.DataFrame({\"frame_number\":filenames})\n",
    "    df_rotation = pd.DataFrame({\"frame_number\":filenames})\n",
    "\n",
    "    now = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "\n",
    "    rotations = [0,1,2]\n",
    "    translations = [[0,0,0],[1,0,0],[2,0,0],[3,0,0],[3,3,0],[5,5,0],[6,6,0],[7,7,0],[10,10,0]]\n",
    "    if translation_number is not None:\n",
    "        translations = [translations[translation_number]]\n",
    "\n",
    "    # translations = [[0,0,0],[1,1,0],[5,5,0],[10,10,0]]\n",
    "    for translation in translations:\n",
    "        print(translation)\n",
    "        i = 1\n",
    "        translation_error = []\n",
    "        rotation_error = []\n",
    "        for idx, frame in enumerate(frames):\n",
    "            print(str(idx) + \" / \" + str(len(frames)) + \" \")\n",
    "\n",
    "            temp_frame = copy.deepcopy(frame)\n",
    "            temp_frame.translate(translation)\n",
    "            ground_truth_rotation = rotate(temp_frame, 0,0,0)\n",
    "\n",
    "            if method == \"p2p\":\n",
    "                evaluation = compute_icp_p2p(temp_frame, target)\n",
    "            if method == \"p2plane\":\n",
    "                evaluation = compute_icp_p2plane(temp_frame, target)\n",
    "            if method == \"global\":\n",
    "                evaluation = compute_global_registration_no_threshold(temp_frame, target_down, frames_fpfh[idx], target_fpfh, voxel_size)\n",
    "            if method == \"fast\":\n",
    "                evaluation = compute_fast_global_registration(temp_frame, target_down, frames_fpfh[idx], target_fpfh, voxel_size)\n",
    "\n",
    "            \n",
    "\n",
    "            # draw_point_clouds([target, temp_frame], transform(temp_frame, evaluation.transformation))\n",
    "            translation_vector, rotation_matrix = decompose_transformation_matrix(evaluation.transformation)\n",
    "            t_error = relative_translation_error(-np.array(translation), translation_vector)\n",
    "            r_error = relative_rotation_error(rotation_matrix,ground_truth_rotation.T)\n",
    "            translation_error.append(t_error)\n",
    "            rotation_error.append(r_error)\n",
    "\n",
    "            if show_tran:\n",
    "                print(f\"Translation error {t_error}, rotation error {r_error}\")\n",
    "                show_transformation(target, temp_frame, evaluation.transformation)\n",
    "\n",
    "\n",
    "        df_translation[str(translation)] = translation_error\n",
    "        df_rotation[str(translation)] = rotation_error\n",
    "        df_translation.to_csv(\"C:\\\\Users\\\\amoff\\\\Documents\\\\Meine Textdokumente\\\\Masterarbeit\\\\Daten\\\\rotated_and_translated\\\\100000000\\\\csv_results\\\\cropped\\\\\" + now + \"_translation_error_\" + suffix + \".csv\")\n",
    "        df_rotation.to_csv(\"C:\\\\Users\\\\amoff\\\\Documents\\\\Meine Textdokumente\\\\Masterarbeit\\\\Daten\\\\rotated_and_translated\\\\100000000\\\\csv_results\\\\cropped\\\\\" + now + \"_rotation_error_\" + suffix + \".csv\")\n",
    "\n",
    "\n",
    "\n",
    "    # Beep(300, 200)\n",
    "    # Beep(300, 200)\n",
    "    # Beep(300, 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_icp_errors(source_folder, target, \"p2p\")\n",
    "compute_icp_errors(source_folder, target, \"p2plane\")\n",
    "compute_icp_errors(source_folder, target, \"global\")\n",
    "compute_icp_errors(source_folder, target, \"fast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Point 2 Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"C:\\\\Users\\\\amoff\\\\Documents\\\\Meine Textdokumente\\\\Masterarbeit\\\\Daten\\\\rotated_and_translated\\\\100000000\\\\csv_results\\\\cropped\\\\\"\n",
    "filename = \"2023_08_01_14_02_40_rotation_error__fast.csv\"\n",
    "\n",
    "filenames = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
    "\n",
    "def plot_errors(folder, filename):\n",
    "    df = pd.read_csv(folder+filename)\n",
    "    df = df.iloc[: , 1:]\n",
    "    ax = df.plot()\n",
    "\n",
    "    arr = filename.split(\"_\")\n",
    "    method = arr[8].split(\".\")[0]\n",
    "    ax.set_ylabel(arr[6] + \" \" + arr[7])\n",
    "    ax.set_xlabel('Frame')\n",
    "    ax.set_title(method + \" \" + arr[6] + \" \" + arr[7])\n",
    "    \n",
    "\n",
    "for filename in filenames:\n",
    "    plot_errors(folder, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_icp_errors(source_folder, target, \"global\", frame_number=3, translation_number=8, show_tran=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vehlocalization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
