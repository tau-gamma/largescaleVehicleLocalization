{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy\n",
    "from os import listdir\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import time \n",
    "from winsound import Beep\n",
    "\n",
    "treg = o3d.t.pipelines.registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_point_clouds(point_clouds, black_point_cloud = None):\n",
    "    pc_copy = []\n",
    "    colors = [[1, 0.706, 0], [0, 0.651, 0.929], [0.3, 0.351, 0.529]]\n",
    "    for idx, x in enumerate(point_clouds):\n",
    "        temp = copy.deepcopy(x)\n",
    "        if idx < len(colors):\n",
    "            temp.paint_uniform_color(colors[idx])\n",
    "        else:\n",
    "            temp.paint_uniform_color(np.random.rand(3))\n",
    "        pc_copy.append(temp)\n",
    "    \n",
    "    if black_point_cloud is not None:\n",
    "        temp = copy.deepcopy(black_point_cloud)\n",
    "        temp.paint_uniform_color([0,0,0])\n",
    "        pc_copy.append(temp)\n",
    "   \n",
    "    o3d.visualization.draw_geometries(pc_copy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = \"C:\\\\Users\\\\amoff\\\\Documents\\\\Meine Textdokumente\\\\Masterarbeit\\\\Daten\\\\rotated_and_translated\\\\100000000\\\\ground_removed_frames\\\\\"\n",
    "\n",
    "target_path = \"C:\\\\Users\\\\amoff\\\\Documents\\\\Meine Textdokumente\\\\Masterarbeit\\\\LiDAR_Punktwolke-RevA-201455_Vermessungsdaten\\\\Cleaned Export\\\\intersection_dirty\\\\intersection_dirty2_xyzi_down_transformed_compressed_ground_removed.pcd\"\n",
    "target = o3d.io.read_point_cloud(target_path)\n",
    "voxel_size = 1\n",
    "target = target.voxel_down_sample(voxel_size)\n",
    "# target.estimate_normals()\n",
    "\n",
    "filenames = listdir(source_folder)[:]\n",
    "frames = [target]\n",
    "for file in filenames:\n",
    "    frames.append(o3d.io.read_point_cloud(source_folder + file))\n",
    "\n",
    "draw_point_clouds(frames)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_registration(source, target):\n",
    "    max_correspondence_distance = 0.5\n",
    "    evaluation = o3d.pipelines.registration.evaluate_registration( source, target, max_correspondence_distance)\n",
    "    print(evaluation.fitness, evaluation.inlier_rmse, evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = listdir(source_folder)\n",
    "\n",
    "frames = []\n",
    "for file in filenames:\n",
    "    frames.append(o3d.io.read_point_cloud(source_folder + file))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for temp_frame in frames:\n",
    "    print(str(i) + \" / \" + str(len(frames)) + \" \")\n",
    "    compute_registration(temp_frame, target)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(point_cloud, transformation):\n",
    "    temp = copy.deepcopy(point_cloud) \n",
    "    return temp.transform(transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_icp_p2p(source, target):\n",
    "    max_correspondence_distance = 10\n",
    "    # return o3d.pipelines.registration.registration_icp( source, target, threshold, np.identity(4), o3d.pipelines.registration.TransformationEstimationPointToPoint(),  o3d.pipelines.registration.ICPConvergenceCriteria(relative_fitness=1.000000e-07, relative_rmse=1.000000e-07,))#max_iteration = 2000,\n",
    "    return o3d.pipelines.registration.registration_icp( source, target, max_correspondence_distance, np.identity(4), o3d.pipelines.registration.TransformationEstimationPointToPoint())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_icp_p2plane(source, target):\n",
    "    max_correspondence_distance = 0.05\n",
    "    return o3d.pipelines.registration.registration_icp( source, target, max_correspondence_distance, np.identity(4), o3d.pipelines.registration.TransformationEstimationPointToPlane())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_icp_multi_scale(source, target):\n",
    "    draw_point_clouds([source], target)\n",
    "    voxel_sizes = o3d.utility.DoubleVector([0.1, 0.05, 0.025])\n",
    "\n",
    "    # List of Convergence-Criteria for Multi-Scale ICP:\n",
    "    criteria_list = [\n",
    "        treg.ICPConvergenceCriteria(relative_fitness=0.0001, relative_rmse=0.0001, max_iteration=20),\n",
    "        treg.ICPConvergenceCriteria(0.00001, 0.00001, 15),\n",
    "        treg.ICPConvergenceCriteria(0.000001, 0.000001, 10)\n",
    "    ]\n",
    "\n",
    "    # `max_correspondence_distances` for Multi-Scale ICP (o3d.utility.DoubleVector):\n",
    "    max_correspondence_distances = o3d.utility.DoubleVector([0.3, 0.14, 0.07])\n",
    "\n",
    "    # Initial alignment or source to target transform.\n",
    "    init_source_to_target = o3d.core.Tensor.eye(4, o3d.core.Dtype.Float32)\n",
    "\n",
    "    # Select the `Estimation Method`, and `Robust Kernel` (for outlier-rejection).\n",
    "    estimation = treg.TransformationEstimationPointToPlane()\n",
    "\n",
    "    # Save iteration wise `fitness`, `inlier_rmse`, etc. to analyse and tune result.\n",
    "    callback_after_iteration = lambda loss_log_map : print(\"Iteration Index: {}, Scale Index: {}, Scale Iteration Index: {}, Fitness: {}, Inlier RMSE: {},\".format(\n",
    "        loss_log_map[\"iteration_index\"].item(),\n",
    "        loss_log_map[\"scale_index\"].item(),\n",
    "        loss_log_map[\"scale_iteration_index\"].item(),\n",
    "        loss_log_map[\"fitness\"].item(),\n",
    "        loss_log_map[\"inlier_rmse\"].item()))\n",
    "\n",
    "    # Setting Verbosity to Debug, helps in fine-tuning the performance.\n",
    "    # o3d.utility.set_verbosity_level(o3d.utility.VerbosityLevel.Debug)\n",
    "\n",
    "    s = time.time()\n",
    "\n",
    "    registration_ms_icp = treg.multi_scale_icp(source, target, \n",
    "                                               voxel_sizes,\n",
    "                                            criteria_list,\n",
    "                                            max_correspondence_distances,\n",
    "                                            # init_source_to_target,\n",
    "                                            # estimation,\n",
    "                                            # callback_after_iteration\n",
    "                                            )\n",
    "\n",
    "    ms_icp_time = time.time() - s\n",
    "    print(\"Time taken by Multi-Scale ICP: \", ms_icp_time)\n",
    "    print(\"Inlier Fitness: \", registration_ms_icp.fitness)\n",
    "    print(\"Inlier RMSE: \", registration_ms_icp.inlier_rmse)\n",
    "    show_transformation(target, source, registration_ms_icp.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_point_clouds([frames[2]], target)\n",
    "compute_icp_multi_scale(frames[2], target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_transformation(target, source, transformation):\n",
    "    draw_point_clouds([target, transform(source, transformation)], source)\n",
    "    # draw_point_clouds([target, ], source)\n",
    "\n",
    "def rotate(point_cloud, x_degrees,y_degrees = 0, z_degrees = 0):\n",
    "    R = point_cloud.get_rotation_matrix_from_xyz(np.pi/180 * np.array([z_degrees, y_degrees,x_degrees]))\n",
    "    point_cloud.rotate(R)\n",
    "    return R\n",
    "\n",
    "def relative_translation_error(translation_vector1, translation_vector2):\n",
    "    return np.linalg.norm(translation_vector1-translation_vector2)\n",
    "\n",
    "def relative_rotation_error(rotation, ground_truth_rotation):\n",
    "    return np.arccos((np.trace(np.matmul(rotation, ground_truth_rotation))-1)/2)\n",
    "\n",
    "def decompose_transformation_matrix(transformation):\n",
    "    translation = transformation[0:3, 3]\n",
    "    rotation = transformation[0:3, 0:3]\n",
    "    return translation, rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = listdir(source_folder)[5:7]\n",
    "frames = []\n",
    "for file in filenames:\n",
    "    frames.append(o3d.io.read_point_cloud(source_folder + file))\n",
    "    \n",
    "df_translation = pd.DataFrame({\"frame_number\":filenames})\n",
    "df_rotation = pd.DataFrame({\"frame_number\":filenames})\n",
    "\n",
    "# suffix = \"relative_fitness=1e-07_rel_rmse=1e-07_p2plane\"\n",
    "suffix = \"\"\n",
    "x = 1\n",
    "display_evaluation = None\n",
    "# rotations = [0,1,2]\n",
    "translations = [[0,0,0],[1,0,0],[2,0,0],[3,0,0],[3,3,0],[5,5,0],[10,10,0]][x:x+1]\n",
    "for translation in translations:\n",
    "    print(translation)\n",
    "    translation_error = []\n",
    "    rotation_error = []\n",
    "    for idx, frame in enumerate(frames):\n",
    "        print(str(idx) + \" / \" + str(len(frames)) + \" \")\n",
    "\n",
    "        temp_frame = copy.deepcopy(frame)\n",
    "        temp_frame.translate(translation)\n",
    "        ground_truth_rotation = rotate(temp_frame, 0,0,0)\n",
    "\n",
    "        # evaluation = compute_icp_p2p(temp_frame, target)\n",
    "        evaluation = compute_icp_p2p(temp_frame, target)\n",
    "        display_evaluation = evaluation \n",
    "\n",
    "        # draw_point_clouds([target, temp_frame], transform(temp_frame, evaluation.transformation))\n",
    "        translation_vector, rotation_matrix = decompose_transformation_matrix(evaluation.transformation)\n",
    "        t_error = relative_translation_error(-np.array(translation), translation_vector)\n",
    "        r_error = relative_rotation_error(rotation_matrix,ground_truth_rotation.T)\n",
    "        translation_error.append(t_error)\n",
    "        rotation_error.append(r_error)\n",
    "        \n",
    "        \n",
    "        show_transformation(target, temp_frame, evaluation.transformation)\n",
    "        \n",
    "\n",
    "    df_translation[str(translation)] = translation_error\n",
    "    df_rotation[str(translation)] = rotation_error\n",
    "\n",
    "now = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "df_translation.to_csv(\"C:\\\\Users\\\\amoff\\\\Documents\\\\Meine Textdokumente\\\\Masterarbeit\\\\Daten\\\\rotated_and_translated\\\\100000000\\\\csv_results\\\\ground_removed\\\\\"+now+\"_local_registration_translation_error_\" + suffix + \".csv\")\n",
    "df_rotation.to_csv(\"C:\\\\Users\\\\amoff\\\\Documents\\\\Meine Textdokumente\\\\Masterarbeit\\\\Daten\\\\rotated_and_translated\\\\100000000\\\\csv_results\\\\ground_removed\\\\\"+now+\"_local_registration_rotation_error_\" + suffix + \".csv\")\n",
    "\n",
    "\n",
    "Beep(300, 200)\n",
    "Beep(300, 200)\n",
    "Beep(300, 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_translation.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rotation.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "t, R = decompose_transformation_matrix(evaluation.transformation)\n",
    "print(t, R)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_transformation(target, frame, display_evaluation.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n",
    "df.to_csv(\"C:\\\\Users\\\\amoff\\\\Documents\\\\Meine Textdokumente\\\\Masterarbeit\\\\Daten\\\\rotated_and_translated\\\\100000000\\\\csv_results\\\\\"+str(df_counter)+\"_local_registration.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"C:\\\\Users\\\\amoff\\\\Documents\\\\Meine Textdokumente\\\\Masterarbeit\\\\Daten\\\\rotated_and_translated\\\\100000000\\\\csv_results\\\\01_local_registration.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [0,0,X]  HÃ¶he\n",
    "\n",
    "temp = copy.deepcopy(arr[1])\n",
    "temp.translate([0,0,10])\n",
    "draw_point_clouds([target,arr[1]], temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rotation Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp = copy.deepcopy(arr[0])\n",
    "x_degree = 10\n",
    "R = rotate(temp, 359)\n",
    "temp2 = copy.deepcopy(temp)\n",
    "temp2.rotate(R.T)\n",
    "temp2.translate((0,10,0))\n",
    "\n",
    "print(R)\n",
    "print(R.T)\n",
    "\n",
    "draw_point_clouds([arr[0],temp2], temp)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "relative_rotation_error(R, np.identity(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp = copy.deepcopy(arr[0])\n",
    "x_degree = 10\n",
    "R = rotate(temp, 359)\n",
    "temp2 = copy.deepcopy(temp)\n",
    "temp2.rotate(R.T)\n",
    "temp2.translate((0,10,0))\n",
    "\n",
    "print(R)\n",
    "print(R.T)\n",
    "\n",
    "draw_point_clouds([arr[0],temp2], temp)\n",
    "\n",
    "\n",
    "relative_rotation_error(R, np.identity(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotate(copy.deepcopy(arr[1]), 360,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = copy.deepcopy(arr[0])\n",
    "temp2 = copy.deepcopy(temp)\n",
    "\n",
    "trans_vector = np.array([0,10,2])\n",
    "# temp.translate(trans_vector)\n",
    "\n",
    "temp2.translate(trans_vector*(-1))\n",
    "\n",
    "print(R)\n",
    "\n",
    "draw_point_clouds([arr[4],temp], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_translation_error(np.array([0,10,2]),np.array([0,10,2]),)\n",
    "\n",
    "trans, rot = decompose_transformation_matrix(evaluation.transformation)\n",
    "relative_rotation_error(rot, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation = rot\n",
    "ground_truth_rotation = rot\n",
    "\n",
    "transformation_base = \"C:\\\\Users\\\\amoff\\\\Documents\\\\Meine Textdokumente\\\\Masterarbeit\\\\Daten\\\\rotated_and_translated\\\\100000000\\\\transformation_matrices_2\\\\1667908110_100000000_transformation.txt\"\n",
    "transformation_matrix = np.loadtxt(transformation_base, delimiter=\" \", dtype=np.float32)\n",
    "print(transformation_matrix, \"\\n\\n\")\n",
    "\n",
    "trans, rot2 = decompose_transformation_matrix(transformation_matrix)\n",
    "print(type(rot),\"\\n\\n\\n\", type(rot2), \"\\n\")\n",
    "\n",
    "\n",
    "# np.arccos(np.trace(np.matmul(rotation, rot))/2)\n",
    "np.arccos((np.trace(np.matmul(rotation, rot2))-1)/2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "\n",
    "    radius_normal = voxel_size * 2\n",
    "    pcd_down.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "\n",
    "    radius_feature = voxel_size * 5\n",
    "    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature( pcd_down, o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "    return pcd_down, pcd_fpfh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_global_registration_no_threshold(source_down, target_down, source_fpfh, target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "    return o3d.pipelines.registration.registration_ransac_based_on_feature_matching( source_down, target_down, source_fpfh, target_fpfh, True, distance_threshold)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fast_global_registration(source_down, target_down, source_fpfh, target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 0.5\n",
    "    # result = o3d.pipelines.registration.registration_fgr_based_on_feature_matching( source_down, target_down, source_fpfh, target_fpfh, o3d.pipelines.registration.FastGlobalRegistrationOption( maximum_correspondence_distance=distance_threshold))\n",
    "    return o3d.pipelines.registration.registration_fgr_based_on_feature_matching( source_down, target_down, source_fpfh, target_fpfh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_down = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_size = 1\n",
    "suffix = \"ransac_no_threshold\"\n",
    "\n",
    "\n",
    "filenames = listdir(source_folder)[6:7]\n",
    "if target_down is None:\n",
    "    target_down, target_fpfh = preprocess_point_cloud(target, voxel_size)\n",
    "print(\"Target fpfh computation done\")\n",
    "\n",
    "frames = []\n",
    "frames_fpfh = []\n",
    "for file in filenames:\n",
    "    point_cloud = o3d.io.read_point_cloud(source_folder + file)\n",
    "    source_down, source_fpfh = preprocess_point_cloud(point_cloud, voxel_size) # means 5cm for this dataset\n",
    "    frames.append(source_down)\n",
    "    frames_fpfh.append(source_fpfh)\n",
    "    \n",
    "df_translation = pd.DataFrame({\"frame_number\":filenames})\n",
    "df_rotation = pd.DataFrame({\"frame_number\":filenames})\n",
    "\n",
    "now = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "\n",
    "# rotations = [0,1,2]\n",
    "# translations = [[0,0,0],[1,0,0],[2,0,0],[3,0,0],[3,3,0],[5,5,0],[10,10,0]]\n",
    "translations = [[0,0,0],[1,0,0],[5,5,0],[10,10,0]][2:3]\n",
    "for translation in translations:\n",
    "    print(translation)\n",
    "    i = 1\n",
    "    translation_error = []\n",
    "    rotation_error = []\n",
    "    for idx, frame in enumerate(frames):\n",
    "        print(str(idx) + \" / \" + str(len(frames)) + \" \")\n",
    "\n",
    "        temp_frame = copy.deepcopy(frame)\n",
    "        temp_frame.translate(translation)\n",
    "        ground_truth_rotation = rotate(temp_frame, 0,0,0)\n",
    "\n",
    "        # evaluation = compute_icp_p2p(temp_frame, target)\n",
    "        # evaluation = compute_icp_p2plane(temp_frame, target)\n",
    "        evaluation = compute_global_registration_no_threshold(frame, target_down, frames_fpfh[idx], target_fpfh, voxel_size)\n",
    "        # evaluation = compute_fast_global_registration(frame, target_down, frames_fpfh[idx], target_fpfh, voxel_size)\n",
    "\n",
    "        # draw_point_clouds([target, temp_frame], transform(temp_frame, evaluation.transformation))\n",
    "        translation_vector, rotation_matrix = decompose_transformation_matrix(evaluation.transformation)\n",
    "        t_error = relative_translation_error(-np.array(translation), translation_vector)\n",
    "        r_error = relative_rotation_error(rotation_matrix,ground_truth_rotation.T)\n",
    "        translation_error.append(t_error)\n",
    "        rotation_error.append(r_error)\n",
    "\n",
    "        show_transformation(target, temp_frame, evaluation.transformation)\n",
    "\n",
    "    df_translation[str(translation)] = translation_error\n",
    "    df_rotation[str(translation)] = rotation_error\n",
    "    df_translation.to_csv(\"C:\\\\Users\\\\amoff\\\\Documents\\\\Meine Textdokumente\\\\Masterarbeit\\\\Daten\\\\rotated_and_translated\\\\100000000\\\\csv_results\\\\\"+now+\"_local_registration_translation_error_\" + suffix + \".csv\")\n",
    "    df_rotation.to_csv(\"C:\\\\Users\\\\amoff\\\\Documents\\\\Meine Textdokumente\\\\Masterarbeit\\\\Daten\\\\rotated_and_translated\\\\100000000\\\\csv_results\\\\\"+now+\"_local_registration_rotation_error_\" + suffix + \".csv\")\n",
    "\n",
    "\n",
    "\n",
    "Beep(300, 200)\n",
    "Beep(300, 200)\n",
    "Beep(300, 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beep(300, 200)\n",
    "Beep(300, 200)\n",
    "Beep(300, 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_translation.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rotation.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_sizes = o3d.utility.DoubleVector([0.1, 0.05, 0.025])\n",
    "\n",
    "# List of Convergence-Criteria for Multi-Scale ICP:\n",
    "criteria_list = [\n",
    "    treg.ICPConvergenceCriteria(relative_fitness=0.0001,\n",
    "                                relative_rmse=0.0001,\n",
    "                                max_iteration=20),\n",
    "    treg.ICPConvergenceCriteria(0.00001, 0.00001, 15),\n",
    "    treg.ICPConvergenceCriteria(0.000001, 0.000001, 10)\n",
    "]\n",
    "\n",
    "# `max_correspondence_distances` for Multi-Scale ICP (o3d.utility.DoubleVector):\n",
    "max_correspondence_distances = o3d.utility.DoubleVector([0.3, 0.14, 0.07])\n",
    "\n",
    "# Initial alignment or source to target transform.\n",
    "init_source_to_target = o3d.core.Tensor.eye(4, o3d.core.Dtype.Float32)\n",
    "\n",
    "# Select the `Estimation Method`, and `Robust Kernel` (for outlier-rejection).\n",
    "estimation = treg.TransformationEstimationPointToPlane()\n",
    "\n",
    "# Save iteration wise `fitness`, `inlier_rmse`, etc. to analyse and tune result.\n",
    "callback_after_iteration = lambda loss_log_map : print(\"Iteration Index: {}, Scale Index: {}, Scale Iteration Index: {}, Fitness: {}, Inlier RMSE: {},\".format(\n",
    "    loss_log_map[\"iteration_index\"].item(),\n",
    "    loss_log_map[\"scale_index\"].item(),\n",
    "    loss_log_map[\"scale_iteration_index\"].item(),\n",
    "    loss_log_map[\"fitness\"].item(),\n",
    "    loss_log_map[\"inlier_rmse\"].item()))\n",
    "\n",
    "\n",
    "# Setting Verbosity to Debug, helps in fine-tuning the performance.\n",
    "# o3d.utility.set_verbosity_level(o3d.utility.VerbosityLevel.Debug)\n",
    "\n",
    "s = time.time()\n",
    "\n",
    "registration_ms_icp = treg.multi_scale_icp(source, target, voxel_sizes,\n",
    "                                           criteria_list,\n",
    "                                           max_correspondence_distances,\n",
    "                                           init_source_to_target, estimation,\n",
    "                                           callback_after_iteration)\n",
    "\n",
    "ms_icp_time = time.time() - s\n",
    "print(\"Time taken by Multi-Scale ICP: \", ms_icp_time)\n",
    "print(\"Inlier Fitness: \", registration_ms_icp.fitness)\n",
    "print(\"Inlier RMSE: \", registration_ms_icp.inlier_rmse)\n",
    "\n",
    "draw_registration_result(source, target, registration_ms_icp.transformation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vehlocalization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
